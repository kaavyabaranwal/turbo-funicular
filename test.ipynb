{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec Similarity Results:\n",
      "[[0.9992943  0.9978086  0.99901503 0.9969616  0.99825    0.9879755\n",
      "  0.9882103  0.9905945  0.98555416 0.9868718  0.9729185  0.97818434\n",
      "  0.9836251  0.97857493 0.98245525 0.9966964  0.9929135  0.99635804\n",
      "  0.9947279  0.9868724  0.99167717 0.98907524 0.991978   0.9914845\n",
      "  0.99201125 0.9965451  0.98692256 0.988443   0.9888123  0.99362165]\n",
      " [0.9904594  0.9827363  0.9868343  0.9792856  0.9900706  0.9991852\n",
      "  0.99528784 0.9968176  0.9963294  0.9992756  0.9808547  0.9848486\n",
      "  0.988054   0.9857073  0.98626906 0.9909829  0.9933637  0.9920384\n",
      "  0.99562556 0.99339867 0.99681747 0.99305415 0.9969336  0.9959613\n",
      "  0.9949959  0.98581207 0.9931747  0.99238133 0.99242735 0.9918972 ]\n",
      " [0.9807769  0.96946317 0.9736219  0.9669678  0.9809723  0.98463047\n",
      "  0.98044765 0.98260623 0.98439103 0.9883889  0.99849486 0.99616444\n",
      "  0.9969496  0.9985168  0.9948186  0.98190725 0.9804834  0.98151654\n",
      "  0.9858149  0.9808108  0.9831131  0.9821359  0.9844606  0.9869005\n",
      "  0.9870114  0.97455454 0.9771201  0.98148966 0.98176146 0.97983205]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Train Doc2Vec model on the articles dataset\n",
    "def train_doc2vec_model(documents):\n",
    "    tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
    "    model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    return model\n",
    "\n",
    "# Calculate Doc2Vec similarity\n",
    "def doc2vec_similarity(doc2vec_model, main_articles, articles):\n",
    "    similarities = []\n",
    "    \n",
    "    # Get the vectors for the articles in the dataset\n",
    "    article_vectors = [doc2vec_model.infer_vector(word_tokenize(article.lower())) for article in articles]\n",
    "\n",
    "    for main_article in main_articles:\n",
    "        # Infer vector for the main article\n",
    "        main_vector = doc2vec_model.infer_vector(word_tokenize(main_article.lower()))\n",
    "        \n",
    "        # Calculate cosine similarity between the main article vector and each article vector\n",
    "        sims = cosine_similarity([main_vector], article_vectors)[0]\n",
    "        similarities.append(sims)\n",
    "    \n",
    "    return np.array(similarities)\n",
    "\n",
    "# Load datasets and prepare texts\n",
    "articles_df = pd.read_csv('articles_dataset.csv')\n",
    "main_articles_df = pd.read_csv('main_articles.csv')\n",
    "article_texts = articles_df['content'].tolist()\n",
    "main_article_texts = main_articles_df['content'].tolist()\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "doc2vec_model = train_doc2vec_model(article_texts)\n",
    "\n",
    "# Calculate similarities\n",
    "doc2vec_results = doc2vec_similarity(doc2vec_model, main_article_texts, article_texts)\n",
    "\n",
    "# Print results for debugging\n",
    "print(\"Doc2Vec Similarity Results:\")\n",
    "print(doc2vec_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
